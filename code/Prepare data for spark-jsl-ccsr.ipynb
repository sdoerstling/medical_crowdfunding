{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"gfm.db\")\n",
    "feed = pd.read_sql_query(\"SELECT * FROM feed_tb\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = feed.drop_duplicates('url')\n",
    "\n",
    "feed['nchar']= [len(x) for x in feed['fund_description']]\n",
    "feed = feed[feed['nchar'] >= 100]\n",
    "\n",
    "#regular expression to remove url\n",
    "url_reg = r'(?:(?:http|https):\\/\\/)?([-a-zA-Z0-9.]{2,256}\\.[a-z]{2,4})\\b(?:\\/[-a-zA-Z0-9@:%_\\+.~#?&//=]*)?'\n",
    "\n",
    "#regular expression to remove emojis\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "feed['fund_description'] = [bs(x).get_text().replace(\"\\n\",\"\").replace(u'\\xa0', u' ') for x in feed['fund_description']]\n",
    "feed['fund_description'] = [re.sub(url_reg,\"\",x) for x in feed['fund_description']]\n",
    "feed['fund_description'] = [emoji_pattern.sub(r'', x) for x in feed['fund_description']]\n",
    "feed['fund_description'] = [x.strip() for x in feed['fund_description']]\n",
    "\n",
    "\n",
    "feed['nchar']= [len(x) for x in feed['fund_description']]\n",
    "feed = feed[feed['nchar'] >= 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude non-english campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLanguage(df):\n",
    "    path_to_pretrained_model = 'fasttext_models/lid.176.bin'\n",
    "    fmodel = fasttext.load_model(path_to_pretrained_model)\n",
    "    r = fmodel.predict(feed['fund_description'].to_list())\n",
    "    labels = r[0]\n",
    "    labels = [i[0].split('__')[2] for i in labels]\n",
    "    scores = r[1]\n",
    "    scores = [i[0] for i in scores]\n",
    "    return labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "feed['language'], feed['lang_score'] = GetLanguage(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = feed[feed['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89493"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deidentify urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = feed[['url','fund_description']]\n",
    "feed.loc[:,'url_deid'] = [int(x) for x in range(len(feed))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export map\n",
    "feed[['url','url_deid']].to_csv('spark-jsl-ccsr/deid/url_deid_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format data for export\n",
    "del feed['url']\n",
    "feed = feed.rename(columns={'url_deid':'url','fund_description':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm takes approximately 2 seconds per campaign\n",
    "#let's say we want each chunk to run 12 hours\n",
    "#12*60*60 = 43200 seconds / 2 seconds per campaign = ~22,000 campaigns\n",
    "#so we will split data into 4 chunks\n",
    "\n",
    "dfs = np.array_split(feed, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spark-jsl-ccsr/input_data/feed_chunk_1.json', 'w', encoding='utf-8') as file:\n",
    "    dfs[0].to_json(file, orient=\"records\", force_ascii=False)\n",
    "    \n",
    "with open('spark-jsl-ccsr/input_data/feed_chunk_2.json', 'w', encoding='utf-8') as file:\n",
    "    dfs[1].to_json(file, orient=\"records\", force_ascii=False)\n",
    "    \n",
    "with open('spark-jsl-ccsr/input_data/feed_chunk_3.json', 'w', encoding='utf-8') as file:\n",
    "    dfs[2].to_json(file, orient=\"records\", force_ascii=False)\n",
    "    \n",
    "with open('spark-jsl-ccsr/input_data/feed_chunk_4.json', 'w', encoding='utf-8') as file:\n",
    "    dfs[3].to_json(file, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
