{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Spark-JSL-CCSR.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1hK_9v1NCXWRhyNCAg_9ewbNz6GoYMPKf","authorship_tag":"ABX9TyOWBxihK6YxPU9dFdHLdFGt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XZQ2ZrKZGbOi"},"source":["# Install and import dependencies"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW6Ip9aWF_Wr","executionInfo":{"status":"ok","timestamp":1612746758649,"user_tz":300,"elapsed":180182,"user":{"displayName":"Steven Doerstling","photoUrl":"","userId":"15104894116977045422"}},"outputId":"21a2558b-a789-4c46-ce72-2bc002c565ea"},"source":["from google.colab import files\n","import json\n","import os\n","import csv\n","import io\n","import pandas as pd\n","import numpy as np\n","import copy\n","import spacy\n","\n","#import license keys from drive\n","with open('/content/drive/MyDrive/Crowdfunding/keys.json') as f:\n","    license_keys = json.load(f)\n","\n","secret = license_keys['SECRET']\n","os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n","os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n","os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n","sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n","jsl_version = license_keys[\"JSL_VERSION\"]\n","\n","print ('SparkNLP Version:', sparknlp_version)\n","print ('SparkNLP-JSL Version:', jsl_version)\n","\n","# Install Java\n","! apt-get update -qq\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed -q pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed spark-nlp==$sparknlp_version\n","! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret\n","\n","os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n","\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from pyspark.sql.types import *\n","\n","import sparknlp\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","import sparknlp_jsl\n","\n","spark = sparknlp_jsl.start(secret)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SparkNLP Version: 2.6.5\n","SparkNLP-JSL Version: 2.7.2\n","openjdk version \"11.0.9.1\" 2020-11-04\n","OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n","\u001b[K     |████████████████████████████████| 215.7MB 31kB/s \n","\u001b[K     |████████████████████████████████| 204kB 21.3MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting spark-nlp==2.6.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/1d/9a2a7c17fc3b3aa78b3921167feed4911d5a055833fea390e7741bba0870/spark_nlp-2.6.5-py2.py3-none-any.whl (130kB)\n","\u001b[K     |████████████████████████████████| 133kB 4.0MB/s \n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-2.6.5\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/2.7.2-7ad44c2a1a61c48b6a74446b0a7cb6b97c58dba0\n","Collecting spark-nlp-jsl==2.7.2\n","\u001b[?25l  Downloading https://pypi.johnsnowlabs.com/2.7.2-7ad44c2a1a61c48b6a74446b0a7cb6b97c58dba0/spark-nlp-jsl/spark_nlp_jsl-2.7.2-py3-none-any.whl (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 422kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: spark-nlp==2.6.5 in /usr/local/lib/python3.6/dist-packages (from spark-nlp-jsl==2.7.2) (2.6.5)\n","Installing collected packages: spark-nlp-jsl\n","Successfully installed spark-nlp-jsl-2.7.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"--4ukn3ZG6-N"},"source":["# Define pipeline elements"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8GSUtr2G88p","executionInfo":{"status":"ok","timestamp":1612747374258,"user_tz":300,"elapsed":795784,"user":{"displayName":"Steven Doerstling","photoUrl":"","userId":"15104894116977045422"}},"outputId":"168bf02d-8ba3-4e19-b96c-ba1ffe0b4b34"},"source":["document_assembler = DocumentAssembler() \\\n","  .setInputCol('text')\\\n","  .setOutputCol('document')\n","\n","sentence_detector = SentenceDetector() \\\n","  .setInputCols(['document'])\\\n","  .setOutputCol('sentence')\n","\n","tokenizer = Tokenizer()\\\n","  .setInputCols(['sentence']) \\\n","  .setOutputCol('token')\n"," \n","word_embeddings_clinical = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n","  .setInputCols([\"sentence\", \"token\"])\\\n","  .setOutputCol(\"embeddings\")\n","\n","ner_jsl = NerDLModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n","  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n","  .setOutputCol(\"ner\")\n","\n","ner_converter_diagnosis = NerConverter() \\\n","  .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n","  .setOutputCol(\"ner_chunk\")\\\n","  .setWhiteList(['Diagnosis'])\n","\n","chunk_embeddings = ChunkEmbeddings()\\\n","    .setInputCols([\"ner_chunk\", \"embeddings\"])\\\n","    .setOutputCol(\"chunk_embeddings\")\n"," \n","c2doc = Chunk2Doc().setInputCols(\"ner_chunk\").setOutputCol(\"ner_chunk_doc\") \n","\n","sbiobert_embedder = BertSentenceEmbeddings\\\n","  .pretrained(\"sbiobert_base_cased_mli\",'en','clinical/models')\\\n","  .setInputCols([\"ner_chunk_doc\"])\\\n","  .setOutputCol(\"sbert_embeddings\")\n","\n","sbert_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_icd10cm_augmented\",\"en\", \"clinical/models\") \\\n","  .setInputCols([\"ner_chunk\", \"sbert_embeddings\"]) \\\n","  .setOutputCol(\"icd10cm_code\")\\\n","  .setDistanceFunction(\"EUCLIDEAN\")\n","\n","pipeline= Pipeline(\n","    stages = [\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        word_embeddings_clinical,\n","        ner_jsl,\n","        ner_converter_diagnosis,\n","        chunk_embeddings,\n","        c2doc,\n","        sbiobert_embedder,\n","        sbert_resolver])\n","\n","empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","pipeline_model = pipeline.fit(empty_df)\n","light_pipeline = sparknlp.base.LightPipeline(pipeline_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_jsl download started this may take some time.\n","Approximate size to download 14 MB\n","[OK!]\n","sbiobert_base_cased_mli download started this may take some time.\n","Approximate size to download 384.3 MB\n","[OK!]\n","sbiobertresolve_icd10cm_augmented download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"26JMoQAFIabW"},"source":["# Define functions"]},{"cell_type":"code","metadata":{"id":"un1bjnoQIZJH"},"source":["def get_codes (light, code, text, url):\n","\n","  '''\n","  example call: get_codes(light_pipeline, 'icd10cm_code', FEED_TEXT, FEED_URL)\n","  '''\n","\n","  full_light_result = light.fullAnnotate(text)\n","\n","  urls = []\n","  chunks = []\n","  begin = []\n","  end = []\n","  sent = []\n","  codes = []\n","  results = []\n","  resolutions = []\n","  res_distances = []\n","\n","  for chunk, code in zip(full_light_result[0]['ner_chunk'], full_light_result[0][code]):\n","      \n","      urls.append(url)\n","      chunks.append(chunk.result)\n","      begin.append(chunk.begin)\n","      end.append(chunk.end)\n","      sent.append(chunk.metadata['sentence'])\n","      codes.append(code.result) \n","      results.append(code.metadata['all_k_results'])\n","      resolutions.append(code.metadata['all_k_resolutions'])\n","      res_distances.append(code.metadata['all_k_distances'])\n","    \n","\n","  df = pd.DataFrame({'url':urls,\n","                    'chunks':chunks, \n","                     'begin': begin, \n","                     'end':end, \n","                     'sent':sent,\n","                    'code':codes,\n","                     'results':results,\n","                    'resolutions':resolutions,\n","                     'res_distances':res_distances})\n","\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzrK11yrUw8t"},"source":["import itertools\n","\n","def run_pipeline(feed):\n","  \n","  r = []\n","\n","  for index, row in feed.iterrows():\n","    url = row['url']\n","    text = row['text']\n","    er_results = get_codes(light_pipeline, 'icd10cm_code', text, url)\n","    r.append(er_results)\n","  \n","  #return concatenated pandas dataframes\n","  df = pd.concat(r)\n","  \n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qxE_qPIQJu5u"},"source":["# Import and process feed data"]},{"cell_type":"code","metadata":{"id":"hr8jgTAAJz0V"},"source":["#crowdfunding/json/rounds_3-6_for_prodigy.json\n","with open('/content/drive/MyDrive/Crowdfunding/spark-jsl-ccsr/input_data/feed_chunk_4.json') as json_file:\n","    feed = json.load(json_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NAQyKVQDMX6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612747380477,"user_tz":300,"elapsed":797149,"user":{"displayName":"Steven Doerstling","photoUrl":"","userId":"15104894116977045422"}},"outputId":"181774f3-5905-4c30-f029-351a97a45503"},"source":["feed = pd.DataFrame(feed)\n","print(feed.shape)\n","feed.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(22373, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>UPDATE: Since this campaign was started, we ha...</td>\n","      <td>67120</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Saturday February 22nd my brother Eric had fal...</td>\n","      <td>67121</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hey guys! I don’t like asking for help but I f...</td>\n","      <td>67122</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Talycia Spivey is a wife and mother of one, wi...</td>\n","      <td>67123</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Luther Coleman, a dedicated advocate to his fr...</td>\n","      <td>67124</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text    url\n","0  UPDATE: Since this campaign was started, we ha...  67120\n","1  Saturday February 22nd my brother Eric had fal...  67121\n","2  Hey guys! I don’t like asking for help but I f...  67122\n","3  Talycia Spivey is a wife and mother of one, wi...  67123\n","4  Luther Coleman, a dedicated advocate to his fr...  67124"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"yz2Fx61UkvzO"},"source":["### Text preprocessing"]},{"cell_type":"markdown","metadata":{"id":"eTiynw5utqsi"},"source":["Text has already had the following preprocessing steps in \"Make qualtrics survey\" notebook\n","\n","\n","```\n","feed = feed.drop_duplicates('url')\n","\n","feed['nchar']= [len(x) for x in feed['fund_description']]\n","feed = feed[feed['nchar'] >= 100]\n","\n","#regular expression to remove url\n","url_reg = r'(?:(?:http|https):\\/\\/)?([-a-zA-Z0-9.]{2,256}\\.[a-z]{2,4})\\b(?:\\/[-a-zA-Z0-9@:%_\\+.~#?&//=]*)?'\n","\n","#regular expression to remove emojis\n","emoji_pattern = re.compile(\"[\"\n","        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n","        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n","        u\"\\U0001F600-\\U0001F64F\"\n","        u\"\\U00002702-\\U000027B0\"\n","        u\"\\U000024C2-\\U0001F251\"\n","        u\"\\U0001f926-\\U0001f937\"\n","        u\"\\U0001F1F2\"\n","        u\"\\U0001F1F4\"\n","        u\"\\U0001F620\"\n","        u\"\\u200d\"\n","        u\"\\u2640-\\u2642\"\n","        \"]+\", flags=re.UNICODE)\n","\n","feed['fund_description'] = [bs(x).get_text().replace(\"\\n\",\"\").replace(u'\\xa0', u' ') for x in feed['fund_description']]\n","feed['fund_description'] = [re.sub(url_reg,\"\",x) for x in feed['fund_description']]\n","feed['fund_description'] = [emoji_pattern.sub(r'', x) for x in feed['fund_description']]\n","feed['fund_description'] = [x.strip() for x in feed['fund_description']]\n","\n","\n","feed['nchar']= [len(x) for x in feed['fund_description']]\n","feed = feed[feed['nchar'] >= 100]\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hM6qlnJCIx1d"},"source":["The spark tokenizer does not work reliably to tokenize on punctuation without whitespace e.g. \"end.Beginning\"\n","\n","So will preprocess this manually to split tokens by .,!?"]},{"cell_type":"code","metadata":{"id":"GQsGQqJAJhwz"},"source":["import re\n","\n","def CustomTokenize(df):\n","  r = []\n","  for i in range(len(df)):\n","    string = re.sub(r'(?<=[.,!\\\\?])(?=[^\\s])', r' ', df['text'][i])\n","    r.append(string)\n","  return r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcChk7b7MtRo"},"source":["feed.loc[:,'text_clean'] = CustomTokenize(feed)\n","del feed['text']\n","feed = feed.rename(columns={'text_clean':'text'})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rmuR0tYGV3gM"},"source":["# Run pipeline"]},{"cell_type":"code","metadata":{"id":"VCrN83P0V13p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612808476758,"user_tz":300,"elapsed":2963160,"user":{"displayName":"Steven Doerstling","photoUrl":"","userId":"15104894116977045422"}},"outputId":"4c52855e-57da-458d-fb52-86d49fbdf5af"},"source":["%time r = run_pipeline(feed)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["CPU times: user 1h 41min 45s, sys: 24min 39s, total: 2h 6min 24s\n","Wall time: 16h 58min 8s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n1jy3NtgV-Lu","executionInfo":{"status":"ok","timestamp":1612808477899,"user_tz":300,"elapsed":1150,"user":{"displayName":"Steven Doerstling","photoUrl":"","userId":"15104894116977045422"}}},"source":["r.to_csv('/content/drive/MyDrive/Crowdfunding/spark-jsl-ccsr/output_data/feed_chunk_4.csv', index=False)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnOzANFsa_la"},"source":[""],"execution_count":null,"outputs":[]}]}