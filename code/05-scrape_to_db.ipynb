{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "from itertools import chain\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import xmltodict\n",
    "from xml.etree import ElementTree as ET\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/db/gfm.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get json files of scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = '../data/scraping/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape_tb\n",
    "def make_scrape_tb(data):\n",
    "    scrape_tb = pd.DataFrame([i['scrape'] for i in data])\n",
    "    scrape_tb.to_sql('scrape_tb', conn, if_exists='append', index = False)\n",
    "\n",
    "#feed_tb\n",
    "def make_feed_tb(data):\n",
    "    feed = pd.DataFrame(i['feed']['campaign'] for i in data if i['feed'] is not None)\n",
    "    feed['url'] = [\"https://www.gofundme.com/f/\" + s for s in feed['url']]\n",
    "    feed['city'] = [i['city'] for i in feed['location']]\n",
    "    feed['country'] = [i['country'] for i in feed['location']]\n",
    "    feed['postal_code'] = [i['postal_code'] for i in feed['location']]\n",
    "    feed['bene_id'] = [i['id'] for i in feed['beneficiary']]\n",
    "    feed['bene_user_id'] = [i['user_id'] for i in feed['beneficiary']]\n",
    "    feed['bene_person_id'] = [i['person_id'] for i in feed['beneficiary']]\n",
    "    feed['bene_first_name'] = [i['first_name'] for i in feed['beneficiary']]\n",
    "    feed['bene_last_name'] = [i['last_name'] for i in feed['beneficiary']]\n",
    "    feed['bene_is_placeholder'] = [i['is_placeholder_bene'] for i in feed['beneficiary']]\n",
    "    feed['bene_profile_url'] = [i['profile_url'] for i in feed['beneficiary']]\n",
    "    feed['campaign_photo_url'] = [i['url'] for i in feed['campaign_photo']]\n",
    "    feed['team_name'] = [i['name'] if i != {} else None for i in feed['team'] ]\n",
    "    feed['team_pic_url'] = [i['team_pic_url'] if i != {} else None for i in feed['team']]\n",
    "    feed['team_media_type'] = [i['media_type'] if i != {} else None for i in feed['team']]\n",
    "    feed['team_pub_attr'] = [i['public_attributions'] if i != {} else None for i in feed['team']]\n",
    "    feed['team_invite_limit'] = [i['team_invite_limit'] if i != {} else None for i in feed['team']]\n",
    "    feed['team_status'] = [i['status'] if i != {} else None for i in feed['team']]\n",
    "    feed['team_created_date'] = [i['created_at'] if i != {} else None for i in feed['team']]\n",
    "    feed['team_updated_date'] = [i['updated_at'] if i != {} else None for i in feed['team']]\n",
    "    donors = pd.DataFrame(i['donor'] for i in data if i['donor'] is not None)\n",
    "    donors['url'] = [i['scrape']['url'] for i in data if i['donor'] is not None]\n",
    "    donors['donor_resp_status'] = [\";\".join(map(str,i)) for i in donors['donor_resp_status']]\n",
    "    del donors['donor_list']\n",
    "    feed = feed.merge(donors, on=\"url\")\n",
    "    del feed['beneficiary']\n",
    "    del feed['charity']\n",
    "    del feed['campaign_photo']\n",
    "    del feed['location']\n",
    "    del feed['tags']\n",
    "    del feed['business']\n",
    "    del feed['team']\n",
    "    del feed['partner']\n",
    "    feed.to_sql('feed_tb', conn, if_exists='append', index = False)\n",
    "    return feed\n",
    "\n",
    "#donation\n",
    "def make_donation_tb(data):\n",
    "    #add url to each donation log\n",
    "    for i in range(0, len(data)):\n",
    "        camp = data[i]\n",
    "        scrape = camp['scrape']\n",
    "        if(scrape['target_cat'] == 1 and scrape['country'] == \"US\" and scrape['activity_status'] == \"active\"):\n",
    "            url = scrape['url']\n",
    "            for don in data[i]['donor']['donor_list']:\n",
    "                don['url'] = url\n",
    "    #make pandas df\n",
    "    donors = pd.DataFrame(i['donor'] for i in data if i['donor'] is not None)\n",
    "    #extract donation log\n",
    "    donation_tb = pd.DataFrame(i for i in chain.from_iterable(donors['donor_list']))\n",
    "    #rename columns\n",
    "    donation_tb.columns = [\"online_id\",\"don_amt\",\"don_offline\",\"don_anon\",\"don_name\",\"don_date\",\"don_profile\",\"don_verified\",\"url\"]\n",
    "    #insert into sql db\n",
    "    donation_tb.to_sql('donation_tb', conn, if_exists='append', index = False)\n",
    "    \n",
    "#team\n",
    "def make_team_member_tb(data, feed):\n",
    "    for i in range(0, len(data)):\n",
    "        camp = data[i]\n",
    "        scrape = camp['scrape']\n",
    "        if(scrape['target_cat'] == 1 and scrape['country'] == \"US\" and scrape['activity_status'] == \"active\"):\n",
    "            url = scrape['url']\n",
    "            for mem in data[i]['feed']['team_members']:\n",
    "                mem['url'] = url\n",
    "    feed_for_team = pd.DataFrame([i['feed'] for i in data if i['feed'] is not None])\n",
    "    if(\"True\" in feed['is_team']):\n",
    "        team_member_tb = pd.DataFrame(i for i in chain.from_iterable(feed_for_team['team_members']))\n",
    "        team_member_tb.columns = [\"team_mem_amt\", \"team_mem_fb\", \"team_mem_first_name\",\"team_mem_gfm_profile\",\"team_mem_id\",\"team_mem_last_name\",\"team_mem_don_attr\",\"team_mem_profile\",\"team_mem_role\",\"team_mem_status\",\"team_mem_person_id\",\"team_mem_locale\",\"url\"]\n",
    "        team_member_tb.to_sql('team_member_tb', conn, if_exists='append', index = False)\n",
    "        \n",
    "#comment\n",
    "def make_comment_tb(data):\n",
    "    for i in range(0, len(data)):\n",
    "        camp = data[i]\n",
    "        scrape = camp['scrape']\n",
    "        if(scrape['target_cat'] == 1 and scrape['country'] == \"US\" and scrape['activity_status'] == \"active\"):\n",
    "            url = scrape['url']\n",
    "            for mem in data[i]['comment']['comment_list']:\n",
    "                mem['url'] = url\n",
    "    comments = pd.DataFrame([i['comment'] for i in data if i['comment'] is not None])\n",
    "    comment_tb = pd.DataFrame(i for i in chain.from_iterable(comments['comment_list']))\n",
    "    comment_tb['donation_amount'] = [i['amount'] if type(i) == dict else None for i in comment_tb['donation']]\n",
    "    comment_tb['is_offline'] = [i['is_offline'] if type(i) == dict else None for i in comment_tb['donation']]\n",
    "    comment_tb['is_anonymous'] = [i['is_anonymous'] if type(i) == dict else None for i in comment_tb['donation']]\n",
    "    comment_tb['created_at'] = [i['created_at'] if type(i) == dict else None for i in comment_tb['donation']]\n",
    "    \n",
    "    #parse out comment variables\n",
    "    try:\n",
    "        comment_tb['comment_id_gfm'] = [i['comment_id'] if type(i) == dict else None for i in comment_tb['comment']]\n",
    "        comment_tb['comment_text'] = [i['comment'] if type(i) == dict else None for i in comment_tb['comment']]\n",
    "        comment_tb['status'] = [i['status'] if type(i) == dict else None for i in comment_tb['comment']]\n",
    "        comment_tb['time_stamp'] = [i['timestamp'] if type(i) == dict else None for i in comment_tb['comment']]\n",
    "        comment_tb['profile_url'] = [i['profile_url'] if type(i) == dict else None for i in comment_tb['comment']]\n",
    "        comment_tb['deny_delete'] = [i['deny_delete'] if type(i) == dict else None for i in comment_tb['comment']]\n",
    "    except:\n",
    "        comment_tb['comment_id_gfm'] = [i['comment_id'] if len(i)>0 else None for i in comment_tb['comment']]\n",
    "        comment_tb['comment_text'] = [i['comment'] if len(i)>0 else None for i in comment_tb['comment']]\n",
    "        comment_tb['status'] = [i['status'] if len(i)>0 else None for i in comment_tb['comment']]\n",
    "        comment_tb['time_stamp'] = [i['timestamp'] if len(i)>0 else None for i in comment_tb['comment']]\n",
    "        comment_tb['profile_url'] = [i['profile_url'] if len(i)>0 else None for i in comment_tb['comment']]\n",
    "        comment_tb['deny_delete'] = [i['deny_delete'] if len(i)>0 else None for i in comment_tb['comment']]\n",
    "    \n",
    "    comment_tb['photos'] = [i if type(i) == list else [] for i in comment_tb['photos']]\n",
    "    comment_tb['photos'] = [i[0]['url'] if len(i) > 0 else None for i in comment_tb['photos']]\n",
    "    del comment_tb['donation']\n",
    "    del comment_tb['comment']\n",
    "    del comment_tb['photos']\n",
    "    del comment_tb['timestamp']\n",
    "    #if(\"amount\" in comment_tb.columns):\n",
    "    #    del comment_tb['amount']\n",
    "    comment_tb.to_sql('comment_tb', conn, if_exists='append', index = False)\n",
    "    \n",
    "#update\n",
    "def make_update_tb(data):\n",
    "    for i in range(0, len(data)):\n",
    "        camp = data[i]\n",
    "        scrape = camp['scrape']\n",
    "        if(scrape['target_cat'] == 1 and scrape['country'] == \"US\" and scrape['activity_status'] == \"active\"):\n",
    "            url = scrape['url']\n",
    "            for mem in data[i]['update']['update_list']:\n",
    "                mem['url'] = url\n",
    "    updates = pd.DataFrame([i['update'] for i in data if i['update'] is not None])\n",
    "    update_tb = pd.DataFrame(i for i in chain.from_iterable(updates['update_list']))\n",
    "    if(len(update_tb)>0):\n",
    "        #extract photo url\n",
    "        update_tb['photo_url'] = [i[0]['url'] if len(i)> 0 else None for i in update_tb['photos']]\n",
    "        #remove/reformat data in dictionary format so that it can be inserted into sql\n",
    "        del update_tb['photos']\n",
    "        #rename columns\n",
    "        update_tb = update_tb.rename(columns={'text': 'update_text'})\n",
    "        #send to db\n",
    "        update_tb.to_sql('update_tb', conn, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_file in json_files:\n",
    "    json_file_path = os.path.join(path_to_json, json_file)\n",
    "    with open (json_file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    #send to db\n",
    "    make_scrape_tb(data)\n",
    "    feed = make_feed_tb(data)\n",
    "    make_donation_tb(data)\n",
    "    make_team_member_tb(data, feed)\n",
    "    make_comment_tb(data)\n",
    "    make_update_tb(data)\n",
    "    print(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
